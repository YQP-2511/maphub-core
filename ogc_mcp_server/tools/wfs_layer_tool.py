"""ç®€åŒ–çš„WFSå›¾å±‚å·¥å…·

åŸºäºWFSæ ‡å‡†HTTPè¯·æ±‚ï¼Œæ”¯æŒå®Œæ•´çš„è¿‡æ»¤å’Œæ’åºåŠŸèƒ½
åˆ†ä¸ºå¤šä¸ªæ¸…æ™°çš„æ¨¡å—ï¼šURLæ„å»ºã€è¿‡æ»¤å™¨ã€æ’åºã€æ•°æ®è·å–
"""

import json
import logging
import aiohttp
from typing import Dict, Any, List, Optional, Union
from urllib.parse import urlencode, quote
from fastmcp import FastMCP, Context

logger = logging.getLogger(__name__)

# åˆ›å»ºWFSå›¾å±‚å·¥å…·æœåŠ¡å™¨
wfs_layer_server = FastMCP(name="WFSå›¾å±‚å·¥å…·")

# å¯¼å…¥å…¨å±€å›¾å±‚å­˜å‚¨
from . import visualization_tools


# ==================== æ¨¡å—1: WFS URLæ„å»ºå™¨ ====================

class WFSURLBuilder:
    """WFSè¯·æ±‚URLæ„å»ºå™¨"""
    
    def __init__(self, service_url: str, layer_name: str):
        self.service_url = service_url.rstrip('?&')
        self.layer_name = layer_name
        self.base_params = {
            'service': 'WFS',
            'version': '2.0.0',
            'request': 'GetFeature',
            'typeNames': layer_name,
            'outputFormat': 'application/json'
        }
    
    def build_url(self, 
                  cql_filter: Optional[str] = None,
                  sort_by: Optional[str] = None,
                  max_features: int = 1000,
                  bbox: Optional[List[float]] = None,
                  srs_name: str = "EPSG:4326",
                  property_names: Optional[List[str]] = None) -> str:
        """æ„å»ºå®Œæ•´çš„WFS GetFeature URL
        
        Args:
            cql_filter: CQLè¿‡æ»¤è¡¨è¾¾å¼
            sort_by: æ’åºå­—æ®µï¼Œæ ¼å¼ï¼š'field_name' æˆ– 'field_name+D'(é™åº)
            max_features: æœ€å¤§è¦ç´ æ•°é‡
            bbox: è¾¹ç•Œæ¡† [minx, miny, maxx, maxy]
            srs_name: åæ ‡å‚è€ƒç³»ç»Ÿ
            property_names: æŒ‡å®šè¿”å›çš„å±æ€§å­—æ®µ
            
        Returns:
            å®Œæ•´çš„WFSè¯·æ±‚URL
        """
        params = self.base_params.copy()
        
        # æ·»åŠ åŸºç¡€å‚æ•°
        if max_features > 0:
            # WFS 2.0.0ä½¿ç”¨countå‚æ•°ï¼Œæ—©æœŸç‰ˆæœ¬ä½¿ç”¨maxFeatureså‚æ•°
            if self.base_params.get('version') == '2.0.0':
                params['count'] = str(max_features)
            else:
                params['maxFeatures'] = str(max_features)
        
        if srs_name:
            params['srsName'] = srs_name
        
        # æ·»åŠ ç©ºé—´è¿‡æ»¤
        if bbox and len(bbox) == 4:
            params['bbox'] = f"{bbox[0]},{bbox[1]},{bbox[2]},{bbox[3]},{srs_name}"
        
        # æ·»åŠ å±æ€§é€‰æ‹©
        if property_names:
            params['propertyName'] = ','.join(property_names)
        
        # æ·»åŠ CQLè¿‡æ»¤å™¨
        if cql_filter:
            params['cql_filter'] = cql_filter
        
        # æ·»åŠ æ’åº
        if sort_by:
            params['sortBy'] = sort_by
        
        # æ„å»ºURL
        query_string = urlencode(params, quote_via=quote)
        separator = '&' if '?' in self.service_url else '?'
        
        return f"{self.service_url}{separator}{query_string}"


# ==================== æ¨¡å—2: CQLè¿‡æ»¤å™¨æ„å»ºå™¨ ====================

class CQLFilterBuilder:
    """CQLè¿‡æ»¤å™¨æ„å»ºå™¨ï¼Œæ”¯æŒå¤šç§è¿‡æ»¤æ¡ä»¶ç»„åˆ"""
    
    @staticmethod
    def build_simple_filter(attribute: str, values: Union[str, List[str]], operator: str = "=") -> str:
        """æ„å»ºç®€å•è¿‡æ»¤æ¡ä»¶
        
        Args:
            attribute: å±æ€§å
            values: å€¼æˆ–å€¼åˆ—è¡¨
            operator: æ“ä½œç¬¦ (=, !=, >, <, >=, <=, LIKE, IN, BETWEEN)
            
        Returns:
            CQLè¿‡æ»¤è¡¨è¾¾å¼
        """
        if isinstance(values, str):
            values = [values]
        
        # æ™ºèƒ½å¤„ç†æ•°å€¼å’Œå­—ç¬¦ä¸²
        processed_values = []
        for v in values:
            str_v = str(v)
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ•°å€¼ï¼ˆæ•´æ•°æˆ–å°æ•°ï¼‰
            if CQLFilterBuilder._is_numeric(str_v):
                processed_values.append(str_v)  # æ•°å€¼ä¸åŠ å¼•å·
            else:
                # å­—ç¬¦ä¸²éœ€è¦è½¬ä¹‰å•å¼•å·å¹¶åŠ å¼•å·
                escaped_v = str_v.replace("'", "''")
                processed_values.append(f"'{escaped_v}'")
        
        if operator.upper() == "IN" or (operator == "=" and len(values) > 1):
            return f"{attribute} IN ({', '.join(processed_values)})"
        
        elif operator.upper() == "LIKE":
            # LIKEæ“ä½œç¬¦æ€»æ˜¯éœ€è¦å¼•å·ï¼Œå› ä¸ºå®ƒç”¨äºå­—ç¬¦ä¸²åŒ¹é…
            original_value = str(values[0]).replace("'", "''")
            return f"{attribute} LIKE '%{original_value}%'"
        
        elif operator.upper() == "BETWEEN":
            # BETWEENæ“ä½œç¬¦éœ€è¦ä¸¤ä¸ªå€¼
            if len(processed_values) < 2:
                raise ValueError(f"BETWEENæ“ä½œç¬¦éœ€è¦ä¸¤ä¸ªå€¼ï¼Œä½†åªæä¾›äº† {len(processed_values)} ä¸ª")
            return f"{attribute} BETWEEN {processed_values[0]} AND {processed_values[1]}"
        
        elif operator in ["=", "!=", ">", "<", ">=", "<="]:
            return f"{attribute} {operator} {processed_values[0]}"
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œç¬¦: {operator}")
    
    @staticmethod
    def _is_numeric(value: str) -> bool:
        """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæ•°å€¼ï¼ˆæ•´æ•°æˆ–å°æ•°ï¼‰
        
        Args:
            value: è¦æ£€æŸ¥çš„å­—ç¬¦ä¸²
            
        Returns:
            å¦‚æœæ˜¯æ•°å€¼è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        try:
            float(value)
            return True
        except ValueError:
            return False
    
    @staticmethod
    def build_range_filter(attribute: str, min_value: str, max_value: str) -> str:
        """æ„å»ºèŒƒå›´è¿‡æ»¤æ¡ä»¶"""
        # æ™ºèƒ½å¤„ç†æ•°å€¼å’Œå­—ç¬¦ä¸²
        if CQLFilterBuilder._is_numeric(min_value) and CQLFilterBuilder._is_numeric(max_value):
            return f"{attribute} BETWEEN {min_value} AND {max_value}"
        else:
            min_escaped = str(min_value).replace("'", "''")
            max_escaped = str(max_value).replace("'", "''")
            return f"{attribute} BETWEEN '{min_escaped}' AND '{max_escaped}'"
    
    @staticmethod
    def combine_filters(filters: List[str], logic: str = "AND") -> str:
        """ç»„åˆå¤šä¸ªè¿‡æ»¤æ¡ä»¶
        
        Args:
            filters: è¿‡æ»¤æ¡ä»¶åˆ—è¡¨
            logic: é€»è¾‘æ“ä½œç¬¦ (AND, OR)
            
        Returns:
            ç»„åˆåçš„CQLè¡¨è¾¾å¼
        """
        if not filters:
            return ""
        
        if len(filters) == 1:
            return filters[0]
        
        logic_op = f" {logic.upper()} "
        return f"({logic_op.join(filters)})"
    
    @staticmethod
    def build_from_json(filter_config: Dict[str, Any]) -> str:
        """ä»JSONé…ç½®æ„å»ºCQLè¿‡æ»¤å™¨
        
        JSONæ ¼å¼ç¤ºä¾‹:
        {
            "filters": [
                {"attribute": "CITY_NAME", "values": ["åŒ—äº¬", "ä¸Šæµ·"], "operator": "IN"},
                {"attribute": "POPULATION", "values": ["1000000"], "operator": ">"},
                {"attribute": "LAND_KM", "values": ["100000", "500000"], "operator": "BETWEEN"}
            ],
            "logic": "AND"
        }
        """
        filters_list = filter_config.get("filters", [])
        logic = filter_config.get("logic", "AND")
        
        cql_parts = []
        for filter_item in filters_list:
            attribute = filter_item.get("attribute")
            values = filter_item.get("values", [])
            operator = filter_item.get("operator", "=")
            
            if attribute and values:
                # å¯¹äºBETWEENæ“ä½œç¬¦ï¼Œä½¿ç”¨ä¸“é—¨çš„build_range_filteræ–¹æ³•
                if operator.upper() == "BETWEEN" and len(values) >= 2:
                    cql_part = CQLFilterBuilder.build_range_filter(attribute, values[0], values[1])
                else:
                    cql_part = CQLFilterBuilder.build_simple_filter(attribute, values, operator)
                cql_parts.append(cql_part)
        
        return CQLFilterBuilder.combine_filters(cql_parts, logic)


# ==================== æ¨¡å—3: æ’åºæ„å»ºå™¨ ====================

class SortBuilder:
    """WFSæ’åºå‚æ•°æ„å»ºå™¨"""
    
    @staticmethod
    def build_sort_param(sort_config: Union[str, Dict[str, Any]]) -> str:
        """æ„å»ºsortByå‚æ•°
        
        Args:
            sort_config: æ’åºé…ç½®
                - å­—ç¬¦ä¸²æ ¼å¼: "field_name" æˆ– "field_name+D"
                - å­—å…¸æ ¼å¼: {"attribute": "field_name", "order": "asc|desc"}
                - å¤šå­—æ®µ: [{"attribute": "field1", "order": "asc"}, ...]
                
        Returns:
            sortByå‚æ•°å€¼
        """
        if isinstance(sort_config, str):
            return sort_config
        
        elif isinstance(sort_config, dict):
            attribute = sort_config.get("attribute")
            order = sort_config.get("order", "asc").lower()
            
            if not attribute:
                raise ValueError("æ’åºé…ç½®ç¼ºå°‘attributeå­—æ®µ")
            
            # ä¿®å¤ï¼šä½¿ç”¨ç©ºæ ¼åˆ†éš”æ ¼å¼ï¼Œè¿™æ˜¯WFSæ ‡å‡†æ ¼å¼
            if order == "desc":
                return f"{attribute} D"
            else:
                return f"{attribute} A"
        
        elif isinstance(sort_config, list):
            # å¤šå­—æ®µæ’åº
            sort_parts = []
            for item in sort_config:
                if isinstance(item, dict):
                    part = SortBuilder.build_sort_param(item)
                    sort_parts.append(part)
            return ",".join(sort_parts)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ’åºé…ç½®ç±»å‹: {type(sort_config)}")


# ==================== æ¨¡å—4: æ•°æ®è·å–å™¨ ====================

class WFSDataFetcher:
    """WFSæ•°æ®è·å–å™¨"""
    
    def __init__(self, timeout: int = 60):
        self.timeout = timeout
    
    async def fetch_data(self, url: str, ctx: Optional[Context] = None) -> Dict[str, Any]:
        """è·å–WFSæ•°æ®
        
        Args:
            url: WFSè¯·æ±‚URL
            ctx: MCPä¸Šä¸‹æ–‡
            
        Returns:
            GeoJSONæ ¼å¼çš„æ•°æ®
        """
        if ctx:
            await ctx.info(f"ğŸŒ å‘é€WFSè¯·æ±‚: {url}")
            await ctx.debug(f"ğŸ” å®Œæ•´URL: {url}")
        
        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=self.timeout)) as session:
                async with session.get(url) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        if ctx:
                            await ctx.error(f"HTTP {response.status} é”™è¯¯å“åº”: {error_text[:200]}")
                        raise Exception(f"HTTPé”™è¯¯ {response.status}: {error_text}")
                    
                    content_type = response.headers.get('content-type', '').lower()
                    if 'json' not in content_type:
                        text_content = await response.text()
                        if 'exception' in text_content.lower() or 'error' in text_content.lower():
                            raise Exception(f"WFSæœåŠ¡é”™è¯¯: {text_content[:500]}")
                    
                    data = await response.json()
                    
                    # éªŒè¯GeoJSONæ ¼å¼
                    if not isinstance(data, dict) or data.get("type") != "FeatureCollection":
                        raise Exception("è¿”å›æ•°æ®ä¸æ˜¯æœ‰æ•ˆçš„GeoJSONæ ¼å¼")
                    
                    features = data.get("features", [])
                    if ctx:
                        await ctx.info(f"âœ… æˆåŠŸè·å– {len(features)} ä¸ªè¦ç´ ")
                    
                    return data
                    
        except Exception as e:
            error_msg = f"WFSæ•°æ®è·å–å¤±è´¥: {str(e)}"
            if ctx:
                await ctx.error(error_msg)
            raise Exception(error_msg)


# ==================== æ¨¡å—5: å›¾å±‚ä¿¡æ¯è·å–å™¨ ====================

async def get_layer_info_from_registry(layer_name: str, ctx: Optional[Context] = None) -> Dict[str, Any]:
    """ä»å›¾å±‚æ³¨å†Œè¡¨è·å–å›¾å±‚ä¿¡æ¯
    
    Args:
        layer_name: å›¾å±‚åç§°
        ctx: MCPä¸Šä¸‹æ–‡å¯¹è±¡
        
    Returns:
        å›¾å±‚è¯¦ç»†ä¿¡æ¯å­—å…¸
        
    Raises:
        ValueError: å½“æ— æ³•è·å–å›¾å±‚ä¿¡æ¯æ—¶
    """
    try:
        # ä½¿ç”¨MCPèµ„æºè¯»å–æœºåˆ¶è·å–å›¾å±‚è¯¦æƒ…
        if not ctx:
            raise ValueError("éœ€è¦MCPä¸Šä¸‹æ–‡æ¥è¯»å–èµ„æº")
        
        # è¯»å–å›¾å±‚è¯¦ç»†èµ„æº
        layer_resource_result = await ctx.read_resource(f"ogc://layer/{layer_name}")
        
        if not layer_resource_result or not layer_resource_result[0].content:
            raise ValueError(f"æ— æ³•è·å–å›¾å±‚ '{layer_name}' çš„è¯¦ç»†ä¿¡æ¯")
        
        layer_content = layer_resource_result[0].content
        
        # å¤„ç†ä¸åŒç±»å‹çš„èµ„æºæ•°æ®
        layer_info: Dict[str, Any] = {}
        
        if isinstance(layer_content, str):
            # å­—ç¬¦ä¸²ç±»å‹ï¼Œéœ€è¦JSONè§£æ
            layer_info = json.loads(layer_content)
        elif isinstance(layer_content, bytes):
            # å­—èŠ‚ç±»å‹ï¼Œå…ˆè§£ç å†JSONè§£æ
            layer_info = json.loads(layer_content.decode('utf-8'))
        elif isinstance(layer_content, dict):
            # å­—å…¸ç±»å‹ï¼Œç›´æ¥ä½¿ç”¨
            layer_info = layer_content
        else:
            # å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²å†è§£æ
            layer_info = json.loads(str(layer_content))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
        if isinstance(layer_info, dict) and "error" in layer_info:
            raise ValueError(layer_info["error"])
        
        return layer_info
        
    except json.JSONDecodeError as e:
        error_msg = f"è§£æå›¾å±‚ä¿¡æ¯JSONå¤±è´¥: {str(e)}"
        if ctx:
            await ctx.error(error_msg)
        raise ValueError(error_msg)
    except Exception as e:
        error_msg = f"è·å–å›¾å±‚ä¿¡æ¯å¤±è´¥: {str(e)}"
        if ctx:
            await ctx.error(error_msg)
        raise ValueError(error_msg)


# ==================== ä¸»å·¥å…·å‡½æ•° ====================

@wfs_layer_server.tool(
    name="add_wfs_layer",
    description="""æ·»åŠ WFSçŸ¢é‡å›¾å±‚ï¼Œæ”¯æŒå®Œæ•´çš„è¿‡æ»¤å’Œæ’åºåŠŸèƒ½ã€‚

ğŸ” æŸ¥è¯¢å‚æ•° (JSONæ ¼å¼):
{
  "filters": [
    {"attribute": "CITY_NAME", "values": ["åŒ—äº¬","ä¸Šæµ·"], "operator": "IN"},
    {"attribute": "POPULATION", "values": ["1000000"], "operator": ">"}
  ],
  "sort": {"attribute": "POPULATION", "order": "desc"},
  "limit": 100,
  "logic": "AND"
}

ğŸ“‹ æ”¯æŒçš„æ“ä½œç¬¦:
- ç­‰äº: = 
- ä¸ç­‰äº: !=
- å¤§äº/å°äº: >, <, >=, <=
- åŒ…å«: IN (å¤šå€¼)
- æ¨¡ç³ŠåŒ¹é…: LIKE
- èŒƒå›´: BETWEEN

ğŸ”„ æ’åºé€‰é¡¹:
- å‡åº: {"attribute": "field_name", "order": "asc"}
- é™åº: {"attribute": "field_name", "order": "desc"}
- å¤šå­—æ®µ: [{"attribute": "field1", "order": "asc"}, {"attribute": "field2", "order": "desc"}]

ğŸ’¡ ä½¿ç”¨å»ºè®®:
- å•å±æ€§å¤šå€¼: {"filters": [{"attribute": "CITY_NAME", "values": ["åŒ—äº¬","ä¸Šæµ·"]}]}
- æ•°å€¼æ¯”è¾ƒ: {"filters": [{"attribute": "P_MALE", "values": ["0.5"], "operator": ">"}]}
- æ’åºé™åˆ¶: {"sort": {"attribute":"POPULATION","order":"desc"},"limit":3}
- å¤åˆæŸ¥è¯¢: ç»„åˆè¿‡æ»¤+æ’åº+é™åˆ¶+é€»è¾‘è¿ç®—ç¬¦

ğŸ“Š å¸¸è§æ•°å€¼å­—æ®µç¤ºä¾‹:
- äººå£æ•°é‡: PERSONS (æ•´æ•°)
- ç”·æ€§æ¯”ä¾‹: P_MALE (å°æ•°ï¼Œå¦‚0.493è¡¨ç¤º49.3%)
- åœŸåœ°é¢ç§¯: LAND_KM (å°æ•°)
- æ°´åŸŸé¢ç§¯: WATER_KM (å°æ•°)
""",
    tags={"wfs", "layer", "vector", "filter", "sort", "query", "numeric"}
)
async def add_wfs_layer(
    layer_name: str,
    query: Optional[str] = None,
    max_features: int = 1000,
    layer_title: Optional[str] = None,
    ctx: Optional[Context] = None
) -> Dict[str, Any]:
    """æ·»åŠ WFSå›¾å±‚åˆ°åœ°å›¾
    
    Args:
        layer_name: å›¾å±‚åç§°
        query: JSONæ ¼å¼çš„æŸ¥è¯¢å‚æ•°ï¼ŒåŒ…å«filtersã€sortã€limitã€logicç­‰
        max_features: æœ€å¤§è¦ç´ æ•°é‡
        layer_title: è‡ªå®šä¹‰å›¾å±‚æ ‡é¢˜
        ctx: MCPä¸Šä¸‹æ–‡
        
    Returns:
        æ“ä½œç»“æœå­—å…¸
    """
    try:
        if ctx:
            await ctx.info(f"ğŸ” å¼€å§‹æ·»åŠ WFSå›¾å±‚: {layer_name}")
        
        # è·å–å›¾å±‚ä¿¡æ¯
        layer_info = await get_layer_info_from_registry(layer_name, ctx)
        
        # éªŒè¯WFSæ”¯æŒ
        wfs_params = layer_info.get("access_parameters", {}).get("wfs")
        if not wfs_params:
            supported_services = layer_info.get("metadata", {}).get("supported_services", [])
            raise ValueError(
                f"å›¾å±‚ '{layer_name}' ä¸æ”¯æŒWFSæœåŠ¡ã€‚"
                f"æ”¯æŒçš„æœåŠ¡ç±»å‹: {', '.join(supported_services) if supported_services else 'æ— '}"
            )
        
        # è·å–æœåŠ¡URLå¹¶ç¡®ä¿æ˜¯WFSç«¯ç‚¹
        service_url = layer_info.get("basic_info", {}).get("service_url", "")
        if not service_url:
            raise ValueError(f"å›¾å±‚ '{layer_name}' ç¼ºå°‘æœåŠ¡URL")
        
        # ç¡®ä¿æœåŠ¡URLæŒ‡å‘WFSç«¯ç‚¹
        if "wmts" in service_url.lower():
            # å¦‚æœæ˜¯WMTS URLï¼Œè½¬æ¢ä¸ºWFS URL
            service_url = service_url.replace("/gwc/service/wmts", "/wfs").replace("/wmts", "/wfs")
        elif not service_url.endswith(("/wfs", "/ows")):
            # å¦‚æœä¸æ˜¯æ ‡å‡†çš„WFSç«¯ç‚¹ï¼Œæ·»åŠ /wfs
            if service_url.endswith("/"):
                service_url = service_url + "wfs"
            else:
                service_url = service_url + "/wfs"
        
        if ctx:
            await ctx.debug(f"ğŸ”§ ä¼˜åŒ–åçš„WFSæœåŠ¡URL: {service_url}")
        
        # è§£ææŸ¥è¯¢å‚æ•°
        query_config = {}
        if query:
            try:
                query_config = json.loads(query)
            except json.JSONDecodeError as e:
                raise ValueError(f"æŸ¥è¯¢å‚æ•°JSONæ ¼å¼é”™è¯¯: {str(e)}")
        
        # æ„å»ºURL
        url_builder = WFSURLBuilder(service_url, layer_name)
        
        # æ„å»ºCQLè¿‡æ»¤å™¨
        cql_filter = None
        if query_config.get("filters"):
            cql_filter = CQLFilterBuilder.build_from_json(query_config)
            if ctx:
                await ctx.info(f"ğŸ¯ CQLè¿‡æ»¤å™¨: {cql_filter}")
        
        # æ„å»ºæ’åºå‚æ•°
        sort_by = None
        if query_config.get("sort"):
            sort_by = SortBuilder.build_sort_param(query_config["sort"])
            if ctx:
                await ctx.info(f"ğŸ“Š æ’åºå‚æ•°: {sort_by}")
        
        # åº”ç”¨é™åˆ¶
        effective_max_features = query_config.get("limit", max_features)
        
        # æ„å»ºå®Œæ•´URL
        wfs_url = url_builder.build_url(
            cql_filter=cql_filter,
            sort_by=sort_by,
            max_features=effective_max_features,
            srs_name=wfs_params.get("srsName", "EPSG:4326")
        )
        
        if ctx:
            await ctx.debug(f"ğŸ”— æ„å»ºçš„WFS URL: {wfs_url}")
            await ctx.debug(f"ğŸ—ï¸ æœåŠ¡åŸºç¡€URL: {service_url}")
            await ctx.debug(f"ğŸ“‹ WFSå‚æ•°: {wfs_params}")
        
        # è·å–æ•°æ®
        data_fetcher = WFSDataFetcher()
        geojson_data = await data_fetcher.fetch_data(wfs_url, ctx)
        
        # åˆ†æç»“æœ
        features = geojson_data.get("features", [])
        feature_count = len(features)
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå®é™…è·å–çš„è¦ç´ æ•°é‡å’ŒæœŸæœ›çš„æ•°é‡
        if ctx:
            await ctx.info(f"ğŸ“Š å®é™…è·å–è¦ç´ æ•°é‡: {feature_count}")
            await ctx.info(f"ğŸ¯ æœŸæœ›è·å–è¦ç´ æ•°é‡: {effective_max_features}")
            if sort_by:
                await ctx.info(f"ğŸ”„ æ’åºå‚æ•°: {sort_by}")
            
            # å¦‚æœæœ‰æ’åºï¼Œæ˜¾ç¤ºå‰å‡ ä¸ªè¦ç´ çš„å…³é”®å±æ€§
            if sort_by and features:
                # ä¿®å¤ï¼šæ­£ç¡®å¤„ç†å¤šå­—æ®µæ’åºçš„æƒ…å†µ
                sort_config = query_config.get("sort")
                sort_attribute = None
                
                if isinstance(sort_config, dict):
                    sort_attribute = sort_config.get("attribute")
                elif isinstance(sort_config, list) and sort_config:
                    # å¯¹äºå¤šå­—æ®µæ’åºï¼Œæ˜¾ç¤ºç¬¬ä¸€ä¸ªæ’åºå­—æ®µ
                    first_sort = sort_config[0]
                    if isinstance(first_sort, dict):
                        sort_attribute = first_sort.get("attribute")
                
                if sort_attribute:
                    await ctx.info(f"ğŸ“‹ å‰3ä¸ªè¦ç´ çš„{sort_attribute}å€¼:")
                    for i, feature in enumerate(features[:3]):
                        props = feature.get("properties", {})
                        value = props.get(sort_attribute, "N/A")
                        state_name = props.get("STATE_NAME", props.get("NAME", f"è¦ç´ {i+1}"))
                        await ctx.info(f"  {i+1}. {state_name}: {value}")
        
        if feature_count == 0 and (cql_filter or sort_by):
            return {
                "success": False,
                "message": "æŸ¥è¯¢æ¡ä»¶æœªåŒ¹é…åˆ°ä»»ä½•è¦ç´ ",
                "layer_name": layer_name,
                "query_config": query_config,
                "wfs_url": wfs_url,
                "current_layer_count": len(visualization_tools._current_layers)
            }
        
        # åˆ›å»ºå¢å¼ºçš„å›¾å±‚å¯¹è±¡ï¼ŒåŒ…å«æ›´å¤šè°ƒè¯•ä¿¡æ¯
        wfs_layer = {
            "id": f"wfs_{layer_name}_{len(visualization_tools._current_layers)}",
            "name": layer_name,
            "title": layer_title or layer_name,
            "type": "geojson",  # ä¿®æ”¹ä¸ºgeojsonç±»å‹ä»¥åŒ¹é…æ¨¡æ¿å¤„ç†é€»è¾‘
            "service_type": "wfs",  # æ·»åŠ æœåŠ¡ç±»å‹æ ‡è¯†
            "source": "wfs_service",
            "geojson_data": geojson_data,  # ä¿®æ”¹å­—æ®µåä»¥åŒ¹é…æ¨¡æ¿æœŸæœ›
            "data": geojson_data,  # ä¿ç•™åŸå­—æ®µä»¥å…¼å®¹å…¶ä»–é€»è¾‘
            "feature_count": feature_count,
            # æ·»åŠ é»˜è®¤æ ·å¼é…ç½®
            "style": {
                "color": "#3388ff",
                "weight": 2,
                "opacity": 0.8,
                "fillColor": "#3388ff",
                "fillOpacity": 0.2
            },
            "opacity": 0.8,  # æ·»åŠ é€æ˜åº¦å­—æ®µ
            "visible": True,  # æ·»åŠ å¯è§æ€§å­—æ®µ
            "query_info": {
                "has_filter": bool(cql_filter),
                "has_sort": bool(sort_by),
                "cql_filter": cql_filter,
                "sort_by": sort_by,
                "max_features": effective_max_features,
                "requested_limit": query_config.get("limit"),
                "actual_returned": feature_count
            },
            "service_info": {
                "service_url": service_url,
                "layer_name": layer_name,
                "wfs_url": wfs_url
            },
            # æ·»åŠ å›¾å±‚ä¿¡æ¯ä»¥åŒ¹é…æ¨¡æ¿æœŸæœ›
            "layer_info": {
                "service_name": service_url.split('/')[2] if '//' in service_url else "WFSæœåŠ¡",
                "layer_title": layer_title or layer_name,
                "crs": "EPSG:4326"
            },
            "metadata": {
                "created_at": json.dumps({"timestamp": "now"}),
                "source": "wfs_layer_tool_v2"
            },
            # æ·»åŠ å‡ ä½•ç±»å‹ä¿¡æ¯ä»¥ä¾¿å¯è§†åŒ–
            "geometry_type": _detect_geometry_type(geojson_data),
            # æ·»åŠ è¾¹ç•Œæ¡†ä¿¡æ¯
            "bbox": _calculate_bbox(geojson_data)
        }
        
        # æ·»åŠ åˆ°å›¾å±‚åˆ—è¡¨
        visualization_tools._current_layers.append(wfs_layer)
        
        # æ„å»ºæˆåŠŸæ¶ˆæ¯
        success_msg = f"âœ… WFSå›¾å±‚ '{layer_name}' æ·»åŠ æˆåŠŸï¼ŒåŒ…å« {feature_count} ä¸ªè¦ç´ "
        if cql_filter:
            success_msg += f"ï¼Œåº”ç”¨äº†è¿‡æ»¤æ¡ä»¶"
        if sort_by:
            success_msg += f"ï¼Œåº”ç”¨äº†æ’åº"
        
        if ctx:
            await ctx.info(success_msg)
        
        return {
            "success": True,
            "message": success_msg,
            "layer_info": {
                "name": layer_name,
                "title": wfs_layer["title"],
                "type": "wfs",
                "feature_count": feature_count,
                "has_filter": bool(cql_filter),
                "has_sort": bool(sort_by),
                "query_config": query_config
            },
            "current_layer_count": len(visualization_tools._current_layers)
        }
        
    except Exception as e:
        error_msg = f"âŒ æ·»åŠ WFSå›¾å±‚å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        if ctx:
            await ctx.error(error_msg)
        return {
            "success": False,
            "error": error_msg,
            "layer_name": layer_name,
            "current_layer_count": len(visualization_tools._current_layers)
        }


# ==================== è¾…åŠ©å·¥å…· ====================

def _detect_geometry_type(geojson_data: Dict[str, Any]) -> str:
    """æ£€æµ‹GeoJSONæ•°æ®çš„å‡ ä½•ç±»å‹"""
    features = geojson_data.get("features", [])
    if not features:
        return "unknown"
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªè¦ç´ çš„å‡ ä½•ç±»å‹
    first_feature = features[0]
    geometry = first_feature.get("geometry", {})
    return geometry.get("type", "unknown").lower()


def _calculate_bbox(geojson_data: Dict[str, Any]) -> Optional[List[float]]:
    """è®¡ç®—GeoJSONæ•°æ®çš„è¾¹ç•Œæ¡†"""
    features = geojson_data.get("features", [])
    if not features:
        return None
    
    min_x = min_y = float('inf')
    max_x = max_y = float('-inf')
    
    for feature in features:
        geometry = feature.get("geometry", {})
        coords = geometry.get("coordinates", [])
        
        if geometry.get("type") == "Point":
            x, y = coords
            min_x, max_x = min(min_x, x), max(max_x, x)
            min_y, max_y = min(min_y, y), max(max_y, y)
        elif geometry.get("type") in ["LineString", "MultiPoint"]:
            for coord in coords:
                x, y = coord
                min_x, max_x = min(min_x, x), max(max_x, x)
                min_y, max_y = min(min_y, y), max(max_y, y)
        elif geometry.get("type") in ["Polygon", "MultiLineString"]:
            for ring in coords:
                for coord in ring:
                    x, y = coord
                    min_x, max_x = min(min_x, x), max(max_x, x)
                    min_y, max_y = min(min_y, y), max(max_y, y)
        elif geometry.get("type") == "MultiPolygon":
            for polygon in coords:
                for ring in polygon:
                    for coord in ring:
                        x, y = coord
                        min_x, max_x = min(min_x, x), max(max_x, x)
                        min_y, max_y = min(min_y, y), max(max_y, y)
    
    if min_x != float('inf'):
        return [min_x, min_y, max_x, max_y]
    return None
