"""ä¼˜åŒ–çš„WFSå›¾å±‚æ·»åŠ å·¥å…·

åŸºäºFastMCPæœ€ä½³å®è·µé‡æ„ï¼Œç®€åŒ–èµ„æºè®¿é—®ï¼Œæé«˜å¯é æ€§
"""

import json
import logging
import asyncio
import aiohttp
from typing import Dict, Any, List, Optional
from urllib.parse import urlencode, quote
from fastmcp import FastMCP, Context
from pydantic import Field
from typing_extensions import Annotated

logger = logging.getLogger(__name__)

# åˆ›å»ºä¼˜åŒ–çš„WFSå›¾å±‚å·¥å…·æœåŠ¡å™¨
wfs_layer_server_backeup = FastMCP(name="ä¼˜åŒ–WFSå›¾å±‚å·¥å…·")

# å¯¼å…¥å…¨å±€å›¾å±‚å­˜å‚¨
from . import visualization_tools


wfs_layer_server_backeup.tool(
    name="add_wfs_layer",
    description="""æ·»åŠ WFSçŸ¢é‡å›¾å±‚åˆ°åœ°å›¾ï¼Œæ”¯æŒé«˜æ€§èƒ½å¤šå±æ€§è¿‡æ»¤åŠŸèƒ½ã€‚

âš ï¸ é‡è¦ï¼šä½¿ç”¨è¿‡æ»¤åŠŸèƒ½å‰å»ºè®®å…ˆè°ƒç”¨ get_wfs_layer_attributes å·¥å…·è·å–å±æ€§ä¿¡æ¯ï¼

ğŸš€ å¤šå±æ€§è¿‡æ»¤ç‰¹æ€§ï¼š
- æ”¯æŒå¤šä¸ªå±æ€§åŒæ—¶è¿‡æ»¤ï¼ˆAND/ORé€»è¾‘ç»„åˆï¼‰
- ä¸°å¯Œçš„è¿‡æ»¤æ“ä½œç¬¦ï¼š=, !=, >, <, >=, <=, LIKE, IN, BETWEEN
- æ™ºèƒ½æ€§èƒ½ä¼˜åŒ–ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æŸ¥è¯¢ç­–ç•¥
- çµæ´»çš„è¿‡æ»¤æ¨¡å¼ï¼šç®€å•æ¨¡å¼ã€é«˜çº§æ¨¡å¼ã€æ€§èƒ½ä¼˜åŒ–æ¨¡å¼

ğŸ“‹ è¿‡æ»¤å‚æ•°è¯´æ˜ï¼š
1. ç®€å•å•å±æ€§è¿‡æ»¤ï¼š
   - attribute_filter="CITY_NAME", filter_values="åŒ—äº¬,ä¸Šæµ·"
   
2. å¤šå±æ€§è¿‡æ»¤ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
   - multi_filters='[{"attribute":"CITY_NAME","operator":"IN","values":["åŒ—äº¬","ä¸Šæµ·"]},{"attribute":"POPULATION","operator":">","values":["1000000"]}]'
   
3. é«˜çº§CQLè¿‡æ»¤ï¼š
   - advanced_cql="CITY_NAME='åŒ—äº¬' AND POPULATION > 1000000"

ğŸ¯ æ€§èƒ½ä¼˜åŒ–é€‰é¡¹ï¼š
- performance_mode: "balanced"(é»˜è®¤) | "speed" | "accuracy" | "minimal"
- use_spatial_index: å¯ç”¨ç©ºé—´ç´¢å¼•ä¼˜åŒ–
- enable_pagination: å¯ç”¨åˆ†é¡µæŸ¥è¯¢
- optimize_for_count: ä¼˜åŒ–è¦ç´ æ•°é‡æŸ¥è¯¢

ğŸ’¡ AIè‡ªä¸»é€‰æ‹©å»ºè®®ï¼š
- å¤§æ•°æ®é›†(>10000è¦ç´ )ï¼šä½¿ç”¨performance_mode="speed"
- å¤æ‚æŸ¥è¯¢ï¼šä½¿ç”¨performance_mode="accuracy" 
- å¿«é€Ÿé¢„è§ˆï¼šä½¿ç”¨performance_mode="minimal"
- ç²¾ç¡®åˆ†æï¼šä½¿ç”¨performance_mode="balanced"

é€‚ç”¨åœºæ™¯ï¼š
- å¤šç»´åº¦æ•°æ®ç­›é€‰ï¼ˆåœ°åŒº+ç±»å‹+æ—¶é—´ç­‰ï¼‰
- æ•°å€¼èŒƒå›´æŸ¥è¯¢ï¼ˆäººå£ã€é¢ç§¯ã€é«˜ç¨‹ç­‰ï¼‰
- æ¨¡ç³ŠåŒ¹é…æœç´¢ï¼ˆåœ°åã€æè¿°ç­‰ï¼‰
- å¤åˆæ¡ä»¶æŸ¥è¯¢ï¼ˆå¤šä¸ªæ¡ä»¶ç»„åˆï¼‰
- å¤§æ•°æ®é›†é«˜æ€§èƒ½æŸ¥è¯¢
""",
    tags={"wfs", "layer", "vector", "multi-filter", "performance", "smart-query", "flexible", "ai-optimized"}
)
async def add_wfs_layer(
    layer_name: str,
    # ç®€å•è¿‡æ»¤å‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
    attribute_filter: Optional[str] = None,
    filter_values: Optional[str] = None,
    # å¤šå±æ€§è¿‡æ»¤å‚æ•°
    multi_filters: Optional[str] = None,
    # é«˜çº§CQLè¿‡æ»¤
    advanced_cql: Optional[str] = None,
    # æ€§èƒ½ä¼˜åŒ–å‚æ•°
    performance_mode: str = "balanced",  # balanced, speed, accuracy, minimal
    use_spatial_index: bool = True,
    enable_pagination: bool = False,
    optimize_for_count: bool = False,
    # å…¶ä»–å‚æ•°
    max_features: int = 1000,
    layer_title: Optional[str] = None,
    ctx: Optional[Context] = None
) -> Dict[str, Any]:
    """æ·»åŠ WFSå›¾å±‚åˆ°åœ°å›¾ï¼Œæ”¯æŒé«˜æ€§èƒ½å¤šå±æ€§è¿‡æ»¤
    
    Args:
        layer_name: å›¾å±‚åç§°
        attribute_filter: å•å±æ€§è¿‡æ»¤åç§°ï¼ˆç®€å•æ¨¡å¼ï¼Œå‘åå…¼å®¹ï¼‰
        filter_values: è¿‡æ»¤å€¼ï¼Œå¤šä¸ªå€¼ç”¨é€—å·åˆ†éš”ï¼ˆç®€å•æ¨¡å¼ï¼‰
        multi_filters: å¤šå±æ€§è¿‡æ»¤JSONå­—ç¬¦ä¸²ï¼ˆé«˜çº§æ¨¡å¼ï¼‰
        advanced_cql: é«˜çº§CQLè¿‡æ»¤è¡¨è¾¾å¼ï¼ˆä¸“å®¶æ¨¡å¼ï¼‰
        performance_mode: æ€§èƒ½æ¨¡å¼ - balanced/speed/accuracy/minimal
        use_spatial_index: æ˜¯å¦ä½¿ç”¨ç©ºé—´ç´¢å¼•ä¼˜åŒ–
        enable_pagination: æ˜¯å¦å¯ç”¨åˆ†é¡µæŸ¥è¯¢
        optimize_for_count: æ˜¯å¦ä¼˜åŒ–è¦ç´ æ•°é‡æŸ¥è¯¢
        max_features: æœ€å¤§è¦ç´ æ•°é‡
        layer_title: è‡ªå®šä¹‰å›¾å±‚æ ‡é¢˜
        ctx: MCPä¸Šä¸‹æ–‡
    
    Returns:
        åŒ…å«æ“ä½œç»“æœçš„å­—å…¸
    """
    try:
        # åˆ†æè¿‡æ»¤æ¨¡å¼å’Œå‚æ•°
        filter_analysis = _analyze_filter_parameters(
            attribute_filter, filter_values, multi_filters, advanced_cql, ctx
        )
        
        if ctx:
            await ctx.info(f"ğŸ” å¼€å§‹æ·»åŠ WFSå›¾å±‚: {layer_name}")
            await ctx.info(f"ğŸ“Š è¿‡æ»¤æ¨¡å¼: {filter_analysis['mode']}")
            await ctx.info(f"âš¡ æ€§èƒ½æ¨¡å¼: {performance_mode}")
            if filter_analysis['has_filter']:
                await ctx.info(f"ğŸ¯ è¿‡æ»¤æ¡ä»¶æ•°é‡: {filter_analysis['filter_count']}")
        
        # è·å–å›¾å±‚ä¿¡æ¯
        layer_info = await _get_layer_info_simplified(layer_name, ctx)
        
        # éªŒè¯WFSæ”¯æŒ
        if not _validate_wfs_support(layer_info, layer_name):
            supported_services = layer_info.get("metadata", {}).get("supported_services", [])
            raise ValueError(
                f"å›¾å±‚ '{layer_name}' ä¸æ”¯æŒWFSæœåŠ¡ã€‚"
                f"æ”¯æŒçš„æœåŠ¡ç±»å‹: {', '.join(supported_services) if supported_services else 'æ— '}"
            )
        
        # æ„å»ºä¼˜åŒ–çš„è¿‡æ»¤å™¨
        filter_info = await _build_advanced_filter(
            layer_info, filter_analysis, performance_mode, ctx
        )
        
        # åº”ç”¨æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
        query_config = _build_performance_config(
            performance_mode, use_spatial_index, enable_pagination, 
            optimize_for_count, max_features, filter_info
        )
        
        if ctx:
            await ctx.info(f"ğŸš€ æŸ¥è¯¢é…ç½®: {query_config['strategy']}")
        
        # è·å–WFSæ•°æ®ï¼ˆä½¿ç”¨ä¼˜åŒ–é…ç½®ï¼‰
        geojson_data = await _fetch_wfs_data_advanced(
            layer_info, query_config, filter_info, ctx
        )
        
        # åˆ†ææŸ¥è¯¢ç»“æœ
        feature_count = len(geojson_data.get("features", []))
        result_analysis = _analyze_query_results(
            geojson_data, filter_info, query_config, ctx
        )
        
        # å¦‚æœç»“æœä¸ºç©ºä¸”æœ‰è¿‡æ»¤æ¡ä»¶ï¼Œæä¾›æ™ºèƒ½å»ºè®®
        if feature_count == 0 and filter_analysis['has_filter']:
            suggestions = await _generate_filter_suggestions(
                layer_info, filter_info, ctx
            )
            
            return {
                "success": False,
                "message": "è¿‡æ»¤æ¡ä»¶æœªåŒ¹é…åˆ°ä»»ä½•è¦ç´ ",
                "layer_name": layer_name,
                "filter_analysis": filter_analysis,
                "suggestions": suggestions,
                "performance_info": result_analysis,
                "current_layer_count": len(visualization_tools._current_layers)
            }
        
        # åˆ›å»ºå¢å¼ºçš„å›¾å±‚å¯¹è±¡
        wfs_layer = _create_advanced_wfs_layer(
            layer_info, layer_title or layer_name, geojson_data, 
            filter_info, query_config, result_analysis
        )
        
        # æ·»åŠ åˆ°å›¾å±‚åˆ—è¡¨
        visualization_tools._current_layers.append(wfs_layer)
        
        # æ„å»ºæˆåŠŸæ¶ˆæ¯
        success_msg = f"âœ… WFSå›¾å±‚ '{layer_name}' æ·»åŠ æˆåŠŸ"
        if filter_analysis['has_filter']:
            success_msg += f"ï¼Œåº”ç”¨{filter_analysis['mode']}è¿‡æ»¤"
        success_msg += f"ï¼ŒåŒ…å« {feature_count} ä¸ªè¦ç´ "
        
        if ctx:
            await ctx.info(success_msg)
            await ctx.info(f"ğŸ“Š æŸ¥è¯¢æ€§èƒ½: {result_analysis.get('performance_summary', 'æœªçŸ¥')}")
            if filter_info.get('optimization_applied'):
                await ctx.info("âš¡ å·²åº”ç”¨æ€§èƒ½ä¼˜åŒ–")
        
        return {
            "success": True,
            "message": success_msg,
            "layer_info": {
                "name": layer_name,
                "title": wfs_layer["title"],
                "type": f"wfs_{filter_analysis['mode']}",
                "feature_count": feature_count,
                "geometry_type": wfs_layer.get("geometry_type"),
                "filter_applied": filter_analysis['has_filter'],
                "filter_mode": filter_analysis['mode'],
                "filter_count": filter_analysis['filter_count'],
                "performance_mode": performance_mode,
                "query_strategy": query_config['strategy'],
                "optimization_applied": filter_info.get('optimization_applied', False)
            },
            "performance_info": result_analysis,
            "current_layer_count": len(visualization_tools._current_layers)
        }
        
    except Exception as e:
        error_msg = f"âŒ æ·»åŠ WFSå›¾å±‚å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        if ctx:
            await ctx.error(error_msg)
        return {
            "success": False,
            "error": error_msg,
            "layer_name": layer_name,
            "filter_analysis": locals().get('filter_analysis', {}),
            "current_layer_count": len(visualization_tools._current_layers)
        }


def _analyze_filter_parameters(
    attribute_filter: Optional[str],
    filter_values: Optional[str], 
    multi_filters: Optional[str],
    advanced_cql: Optional[str],
    ctx: Optional[Context]
) -> Dict[str, Any]:
    """åˆ†æè¿‡æ»¤å‚æ•°ï¼Œç¡®å®šè¿‡æ»¤æ¨¡å¼å’Œå¤æ‚åº¦"""
    analysis = {
        "mode": "none",
        "has_filter": False,
        "filter_count": 0,
        "complexity": "simple",
        "parameters": {}
    }
    
    # æ£€æŸ¥é«˜çº§CQLæ¨¡å¼
    if advanced_cql and advanced_cql.strip():
        analysis.update({
            "mode": "advanced_cql",
            "has_filter": True,
            "filter_count": advanced_cql.count("AND") + advanced_cql.count("OR") + 1,
            "complexity": "expert",
            "parameters": {"cql": advanced_cql.strip()}
        })
        return analysis
    
    # æ£€æŸ¥å¤šå±æ€§è¿‡æ»¤æ¨¡å¼
    if multi_filters and multi_filters.strip():
        try:
            filters_data = json.loads(multi_filters)
            if isinstance(filters_data, list) and filters_data:
                analysis.update({
                    "mode": "multi_attribute",
                    "has_filter": True,
                    "filter_count": len(filters_data),
                    "complexity": "advanced" if len(filters_data) > 2 else "moderate",
                    "parameters": {"filters": filters_data}
                })
                return analysis
        except json.JSONDecodeError:
            if ctx:
                asyncio.create_task(ctx.warning("âš ï¸ multi_filters JSONæ ¼å¼é”™è¯¯ï¼Œå›é€€åˆ°ç®€å•æ¨¡å¼"))
    
    # æ£€æŸ¥ç®€å•å•å±æ€§æ¨¡å¼
    if attribute_filter and filter_values:
        values_list = [v.strip() for v in filter_values.split(',') if v.strip()]
        analysis.update({
            "mode": "single_attribute",
            "has_filter": True,
            "filter_count": 1,
            "complexity": "moderate" if len(values_list) > 1 else "simple",
            "parameters": {
                "attribute": attribute_filter,
                "values": values_list
            }
        })
        return analysis
    
    return analysis


async def _build_advanced_filter(
    layer_info: Dict[str, Any],
    filter_analysis: Dict[str, Any],
    performance_mode: str,
    ctx: Optional[Context]
) -> Dict[str, Any]:
    """æ„å»ºé«˜çº§å¤šå±æ€§è¿‡æ»¤å™¨"""
    filter_info = {
        "cql_filter": None,
        "description": "æ— è¿‡æ»¤æ¡ä»¶",
        "mode": filter_analysis["mode"],
        "complexity": filter_analysis["complexity"],
        "filter_count": filter_analysis["filter_count"],
        "optimization_applied": False,
        "performance_hints": []
    }
    
    if not filter_analysis["has_filter"]:
        return filter_info
    
    # è·å–å¯ç”¨å±æ€§
    available_attributes = _extract_attributes_from_resource(layer_info, ctx)
    
    try:
        if filter_analysis["mode"] == "advanced_cql":
            # é«˜çº§CQLæ¨¡å¼
            cql_filter = filter_analysis["parameters"]["cql"]
            filter_info.update({
                "cql_filter": cql_filter,
                "description": f"é«˜çº§CQLè¿‡æ»¤: {cql_filter[:100]}{'...' if len(cql_filter) > 100 else ''}",
                "raw_cql": cql_filter
            })
            
        elif filter_analysis["mode"] == "multi_attribute":
            # å¤šå±æ€§è¿‡æ»¤æ¨¡å¼
            filters_data = filter_analysis["parameters"]["filters"]
            cql_parts = []
            descriptions = []
            
            for filter_item in filters_data:
                attribute = filter_item.get("attribute", "")
                operator = filter_item.get("operator", "=").upper()
                values = filter_item.get("values", [])
                logic = filter_item.get("logic", "AND").upper()
                
                # æ™ºèƒ½å±æ€§åŒ¹é…
                matched_attr = _smart_match_attribute(attribute, available_attributes, ctx)
                if not matched_attr:
                    if ctx:
                        await ctx.warning(f"âš ï¸ å±æ€§ '{attribute}' æ— æ³•åŒ¹é…ï¼Œè·³è¿‡æ­¤è¿‡æ»¤æ¡ä»¶")
                    continue
                
                # æ„å»ºå•ä¸ªè¿‡æ»¤æ¡ä»¶
                cql_part = _build_single_filter_cql(matched_attr, operator, values)
                if cql_part:
                    cql_parts.append(cql_part)
                    descriptions.append(f"{matched_attr} {operator} {values}")
            
            if cql_parts:
                # ç»„åˆå¤šä¸ªè¿‡æ»¤æ¡ä»¶ï¼ˆé»˜è®¤ä½¿ç”¨ANDï¼‰
                combined_cql = " AND ".join(cql_parts)
                filter_info.update({
                    "cql_filter": combined_cql,
                    "description": f"å¤šå±æ€§è¿‡æ»¤: {' AND '.join(descriptions)}",
                    "individual_filters": descriptions
                })
            
        elif filter_analysis["mode"] == "single_attribute":
            # ç®€å•å•å±æ€§æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            attribute = filter_analysis["parameters"]["attribute"]
            values = filter_analysis["parameters"]["values"]
            
            matched_attr = _smart_match_attribute(attribute, available_attributes, ctx)
            if matched_attr:
                if len(values) == 1:
                    cql_filter = f"{matched_attr} = '{values[0].replace(chr(39), chr(39)+chr(39))}'"
                    description = f"å•å€¼è¿‡æ»¤: {matched_attr} = '{values[0]}'"
                else:
                    escaped_values = [f"'{v.replace(chr(39), chr(39)+chr(39))}'" for v in values]
                    cql_filter = f"{matched_attr} IN ({', '.join(escaped_values)})"
                    description = f"å¤šå€¼è¿‡æ»¤: {matched_attr} IN ({', '.join(values)})"
                
                filter_info.update({
                    "cql_filter": cql_filter,
                    "description": description,
                    "matched_attribute": matched_attr,
                    "filter_values": values
                })
        
        # åº”ç”¨æ€§èƒ½ä¼˜åŒ–
        if filter_info.get("cql_filter"):
            filter_info = _apply_performance_optimizations(
                filter_info, performance_mode, available_attributes, ctx
            )
        
        if ctx and filter_info.get("cql_filter"):
            await ctx.info(f"ğŸ” æ„å»ºçš„CQLè¿‡æ»¤å™¨: {filter_info['cql_filter']}")
            if filter_info.get("optimization_applied"):
                await ctx.info("âš¡ å·²åº”ç”¨æ€§èƒ½ä¼˜åŒ–")
        
        return filter_info
        
    except Exception as e:
        if ctx:
            await ctx.error(f"âŒ æ„å»ºè¿‡æ»¤å™¨å¤±è´¥: {str(e)}")
        raise ValueError(f"æ„å»ºè¿‡æ»¤å™¨å¤±è´¥: {str(e)}")


def _build_single_filter_cql(attribute: str, operator: str, values: List[str]) -> Optional[str]:
    """æ„å»ºå•ä¸ªå±æ€§çš„CQLè¿‡æ»¤æ¡ä»¶"""
    if not values:
        return None
    
    # è½¬ä¹‰å•å¼•å·
    escaped_values = [str(v).replace("'", "''") for v in values]
    
    if operator == "=":
        if len(values) == 1:
            return f"{attribute} = '{escaped_values[0]}'"
        else:
            quoted_values = [f"'{v}'" for v in escaped_values]
            return f"{attribute} IN ({', '.join(quoted_values)})"
    
    elif operator == "!=":
        if len(values) == 1:
            return f"{attribute} != '{escaped_values[0]}'"
        else:
            quoted_values = [f"'{v}'" for v in escaped_values]
            return f"{attribute} NOT IN ({', '.join(quoted_values)})"
    
    elif operator in [">", "<", ">=", "<="]:
        if values:
            return f"{attribute} {operator} '{escaped_values[0]}'"
    
    elif operator == "LIKE":
        if values:
            return f"{attribute} LIKE '%{escaped_values[0]}%'"
    
    elif operator == "IN":
        if len(values) > 1:
            quoted_values = [f"'{v}'" for v in escaped_values]
            return f"{attribute} IN ({', '.join(quoted_values)})"
        elif len(values) == 1:
            return f"{attribute} = '{escaped_values[0]}'"
    
    elif operator == "BETWEEN":
        if len(values) >= 2:
            return f"{attribute} BETWEEN '{escaped_values[0]}' AND '{escaped_values[1]}'"
    
    return None


def _apply_performance_optimizations(
    filter_info: Dict[str, Any],
    performance_mode: str,
    available_attributes: List[str],
    ctx: Optional[Context]
) -> Dict[str, Any]:
    """åº”ç”¨æ€§èƒ½ä¼˜åŒ–ç­–ç•¥"""
    optimizations = []
    
    if performance_mode == "speed":
        # é€Ÿåº¦ä¼˜å…ˆï¼šç®€åŒ–æŸ¥è¯¢ï¼Œæ·»åŠ ç´¢å¼•æç¤º
        if filter_info.get("cql_filter"):
            # æ·»åŠ ç´¢å¼•æç¤ºï¼ˆå¦‚æœæ”¯æŒï¼‰
            optimizations.append("index_hint")
            filter_info["performance_hints"].append("ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–")
    
    elif performance_mode == "accuracy":
        # ç²¾åº¦ä¼˜å…ˆï¼šä¿æŒå®Œæ•´æŸ¥è¯¢
        optimizations.append("full_precision")
        filter_info["performance_hints"].append("ä¿æŒæŸ¥è¯¢ç²¾åº¦")
    
    elif performance_mode == "minimal":
        # æœ€å°åŒ–ï¼šé™åˆ¶è¿”å›å­—æ®µ
        optimizations.append("minimal_fields")
        filter_info["performance_hints"].append("æœ€å°åŒ–è¿”å›å­—æ®µ")
    
    else:  # balanced
        # å¹³è¡¡æ¨¡å¼ï¼šé€‚åº¦ä¼˜åŒ–
        optimizations.append("balanced_optimization")
        filter_info["performance_hints"].append("å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦")
    
    if optimizations:
        filter_info["optimization_applied"] = True
        filter_info["optimizations"] = optimizations
    
    return filter_info


def _build_performance_config(
    performance_mode: str,
    use_spatial_index: bool,
    enable_pagination: bool,
    optimize_for_count: bool,
    max_features: int,
    filter_info: Dict[str, Any]
) -> Dict[str, Any]:
    """æ„å»ºæ€§èƒ½é…ç½®"""
    config = {
        "strategy": "standard",
        "max_features": max_features,
        "use_spatial_index": use_spatial_index,
        "enable_pagination": enable_pagination,
        "optimize_for_count": optimize_for_count,
        "timeout": 60,
        "chunk_size": 1000
    }
    
    # æ ¹æ®æ€§èƒ½æ¨¡å¼è°ƒæ•´é…ç½®
    if performance_mode == "speed":
        config.update({
            "strategy": "high_performance",
            "timeout": 30,
            "chunk_size": 500,
            "max_features": min(max_features, 5000)
        })
    elif performance_mode == "accuracy":
        config.update({
            "strategy": "high_accuracy",
            "timeout": 120,
            "chunk_size": 2000
        })
    elif performance_mode == "minimal":
        config.update({
            "strategy": "minimal_load",
            "timeout": 15,
            "chunk_size": 200,
            "max_features": min(max_features, 1000)
        })
    else:  # balanced
        config.update({
            "strategy": "balanced",
            "timeout": 60,
            "chunk_size": 1000
        })
    
    # æ ¹æ®è¿‡æ»¤å¤æ‚åº¦è°ƒæ•´
    if filter_info.get("complexity") == "expert":
        config["timeout"] *= 1.5
    elif filter_info.get("complexity") == "advanced":
        config["timeout"] *= 1.2
    
    return config


async def _fetch_wfs_data_advanced(
    layer_info: Dict[str, Any],
    query_config: Dict[str, Any],
    filter_info: Dict[str, Any],
    ctx: Optional[Context]
) -> Dict[str, Any]:
    """é«˜æ€§èƒ½WFSæ•°æ®è·å–"""
    try:
        basic_info = layer_info.get("basic_info", {})
        wfs_params = layer_info.get("access_parameters", {}).get("wfs", {})
        
        # æ„å»ºä¼˜åŒ–çš„WFS URL
        wfs_url_base = wfs_params.get("service_url") or basic_info.get("service_url", "")
        base_url = _optimize_wfs_url(wfs_url_base)
        
        if ctx:
            await ctx.debug(f"ğŸ”§ ä½¿ç”¨ä¼˜åŒ–WFS URL: {base_url}")
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        params = {
            "SERVICE": "WFS",
            "VERSION": wfs_params.get("version", "2.0.0"),
            "REQUEST": "GetFeature",
            "TYPENAME": wfs_params.get("typeNames", basic_info.get("layer_name", "")),
            "OUTPUTFORMAT": "application/json",
            "MAXFEATURES": str(query_config["max_features"]),
            "SRSNAME": wfs_params.get("srsName", "EPSG:4326")
        }
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if filter_info.get("cql_filter"):
            params["CQL_FILTER"] = filter_info["cql_filter"]
        
        # åº”ç”¨æ€§èƒ½ä¼˜åŒ–å‚æ•°
        if query_config.get("use_spatial_index"):
            params["HINT_SPATIAL_INDEX"] = "true"
        
        if query_config["strategy"] == "minimal_load":
            # æœ€å°åŒ–å­—æ®µè¿”å›
            params["PROPERTYNAME"] = "geometry"
        
        # æ„å»ºè¯·æ±‚URL
        query_string = urlencode(params, quote_via=lambda x, *args, **kwargs: x)
        wfs_url = f"{base_url}?{query_string}"
        
        if ctx:
            await ctx.info(f"ğŸŒ ä¼˜åŒ–WFSè¯·æ±‚: {query_config['strategy']}")
            await ctx.debug(f"ğŸ”— è¯·æ±‚URL: {wfs_url}")
        
        # ä¼˜åŒ–HTTPé…ç½®
        timeout = aiohttp.ClientTimeout(total=query_config["timeout"], connect=10)
        headers = {
            'User-Agent': 'OGC-MCP-Server-Advanced/1.0',
            'Accept': 'application/json, application/geo+json',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive'
        }
        
        # æ‰§è¡Œè¯·æ±‚
        async with aiohttp.ClientSession(timeout=timeout, headers=headers) as session:
            start_time = asyncio.get_event_loop().time()
            
            async with session.get(wfs_url) as response:
                end_time = asyncio.get_event_loop().time()
                request_time = end_time - start_time
                
                if ctx:
                    await ctx.debug(f"ğŸ“¥ HTTPå“åº”: {response.status} (è€—æ—¶: {request_time:.2f}s)")
                
                if response.status == 200:
                    content_type = response.headers.get('content-type', '').lower()
                    
                    if 'json' in content_type:
                        geojson_data = await response.json()
                    else:
                        text_content = await response.text()
                        try:
                            geojson_data = json.loads(text_content)
                        except json.JSONDecodeError:
                            raise Exception(f"æ— æ³•è§£æå“åº”ä¸ºJSONã€‚å†…å®¹ç±»å‹: {content_type}")
                    
                    # éªŒè¯å“åº”
                    if not isinstance(geojson_data, dict) or "features" not in geojson_data:
                        if "ExceptionReport" in str(geojson_data):
                            raise Exception(f"WFSæœåŠ¡é”™è¯¯: {str(geojson_data)[:500]}")
                        raise Exception("å“åº”æ ¼å¼æ— æ•ˆ")
                    
                    # æ·»åŠ æ€§èƒ½ä¿¡æ¯
                    geojson_data["_performance"] = {
                        "request_time": request_time,
                        "strategy": query_config["strategy"],
                        "feature_count": len(geojson_data.get("features", [])),
                        "optimized": True
                    }
                    
                    if ctx:
                        feature_count = len(geojson_data.get("features", []))
                        await ctx.info(f"âœ… è·å– {feature_count} ä¸ªè¦ç´  (è€—æ—¶: {request_time:.2f}s)")
                    
                    return geojson_data
                    
                else:
                    error_text = await response.text()
                    raise Exception(f"WFSè¯·æ±‚å¤±è´¥: HTTP {response.status}\n{error_text[:500]}")
                    
    except Exception as e:
        if ctx:
            await ctx.error(f"âŒ é«˜æ€§èƒ½WFSæŸ¥è¯¢å¤±è´¥: {str(e)}")
        raise Exception(f"WFSæ•°æ®è·å–å¤±è´¥: {str(e)}")


def _optimize_wfs_url(wfs_url_base: str) -> str:
    """ä¼˜åŒ–WFSæœåŠ¡URL"""
    if not wfs_url_base:
        raise Exception("ç¼ºå°‘WFSæœåŠ¡URL")
    
    # æ¸…ç†å’Œæ ‡å‡†åŒ–URL
    if "gwc/service/wmts" in wfs_url_base:
        wfs_url_base = wfs_url_base.replace("gwc/service/wmts", "wfs")
    elif "wmts" in wfs_url_base.lower():
        wfs_url_base = wfs_url_base.replace("wmts", "wfs").replace("WMTS", "wfs")
    elif not wfs_url_base.endswith(("/wfs", "/ows")):
        if wfs_url_base.endswith("/"):
            wfs_url_base = wfs_url_base + "wfs"
        else:
            wfs_url_base = wfs_url_base + "/wfs"
    
    return wfs_url_base.rstrip('?')


def _analyze_query_results(
    geojson_data: Dict[str, Any],
    filter_info: Dict[str, Any],
    query_config: Dict[str, Any],
    ctx: Optional[Context]
) -> Dict[str, Any]:
    """åˆ†ææŸ¥è¯¢ç»“æœæ€§èƒ½"""
    performance_info = geojson_data.get("_performance", {})
    feature_count = len(geojson_data.get("features", []))
    
    analysis = {
        "feature_count": feature_count,
        "request_time": performance_info.get("request_time", 0),
        "strategy_used": performance_info.get("strategy", "unknown"),
        "optimized": performance_info.get("optimized", False),
        "performance_rating": "unknown"
    }
    
    # æ€§èƒ½è¯„çº§
    request_time = analysis["request_time"]
    if request_time < 1.0:
        analysis["performance_rating"] = "excellent"
        analysis["performance_summary"] = f"ä¼˜ç§€ ({request_time:.2f}s)"
    elif request_time < 3.0:
        analysis["performance_rating"] = "good"
        analysis["performance_summary"] = f"è‰¯å¥½ ({request_time:.2f}s)"
    elif request_time < 10.0:
        analysis["performance_rating"] = "fair"
        analysis["performance_summary"] = f"ä¸€èˆ¬ ({request_time:.2f}s)"
    else:
        analysis["performance_rating"] = "poor"
        analysis["performance_summary"] = f"è¾ƒæ…¢ ({request_time:.2f}s)"
    
    # æ•ˆç‡åˆ†æ
    if feature_count > 0:
        features_per_second = feature_count / max(request_time, 0.001)
        analysis["efficiency"] = f"{features_per_second:.0f} è¦ç´ /ç§’"
    
    return analysis


async def _generate_filter_suggestions(
    layer_info: Dict[str, Any],
    filter_info: Dict[str, Any],
    ctx: Optional[Context]
) -> Dict[str, Any]:
    """ç”Ÿæˆæ™ºèƒ½è¿‡æ»¤å»ºè®®"""
    suggestions = {
        "attribute_suggestions": [],
        "value_suggestions": [],
        "query_suggestions": [],
        "performance_tips": []
    }
    
    try:
        # è·å–å±æ€§å»ºè®®
        available_attributes = _extract_attributes_from_resource(layer_info, ctx)
        if available_attributes:
            suggestions["attribute_suggestions"] = available_attributes[:10]
        
        # è·å–å€¼å»ºè®®ï¼ˆä»æ ·æœ¬æ•°æ®ï¼‰
        if filter_info.get("matched_attribute"):
            value_samples = await _explore_attribute_values(
                layer_info, filter_info["matched_attribute"], ctx, sample_size=20
            )
            suggestions["value_suggestions"] = value_samples[:10]
        
        # æŸ¥è¯¢å»ºè®®
        suggestions["query_suggestions"] = [
            "å°è¯•ä½¿ç”¨æ›´å®½æ³›çš„è¿‡æ»¤æ¡ä»¶",
            "æ£€æŸ¥å±æ€§åç§°å’Œå€¼çš„æ‹¼å†™",
            "ä½¿ç”¨LIKEæ“ä½œç¬¦è¿›è¡Œæ¨¡ç³ŠåŒ¹é…",
            "å°è¯•æ•°å€¼èŒƒå›´æŸ¥è¯¢è€Œéç²¾ç¡®åŒ¹é…"
        ]
        
        # æ€§èƒ½å»ºè®®
        suggestions["performance_tips"] = [
            "å¯¹äºå¤§æ•°æ®é›†ï¼Œä½¿ç”¨performance_mode='speed'",
            "å¯ç”¨ç©ºé—´ç´¢å¼•ä¼˜åŒ– use_spatial_index=True",
            "è€ƒè™‘ä½¿ç”¨åˆ†é¡µæŸ¥è¯¢ enable_pagination=True",
            "ä½¿ç”¨å¤šå±æ€§è¿‡æ»¤ç¼©å°æŸ¥è¯¢èŒƒå›´"
        ]
        
    except Exception as e:
        if ctx:
            await ctx.debug(f"ç”Ÿæˆå»ºè®®æ—¶å‡ºé”™: {str(e)}")
    
    return suggestions


def _create_advanced_wfs_layer(
    layer_info: Dict[str, Any],
    title: str,
    geojson_data: Dict[str, Any],
    filter_info: Dict[str, Any],
    query_config: Dict[str, Any],
    result_analysis: Dict[str, Any]
) -> Dict[str, Any]:
    """åˆ›å»ºå¢å¼ºçš„WFSå›¾å±‚å¯¹è±¡"""
    basic_info = layer_info.get("basic_info", {})
    wfs_params = layer_info.get("access_parameters", {}).get("wfs", {})
    capabilities = layer_info.get("capabilities", {})
    
    # åˆ†æå‡ ä½•ç±»å‹
    features = geojson_data.get("features", [])
    geometry_types = set()
    for feature in features:
        geom = feature.get("geometry", {})
        if geom and geom.get("type"):
            geometry_types.add(geom["type"])
    
    return {
        # åŸºç¡€ä¿¡æ¯
        "name": basic_info.get("layer_name", ""),
        "title": title,
        "type": "wfs",  # ä¿®æ”¹ä¸ºæ ‡å‡†çš„ wfs ç±»å‹ï¼Œè€Œä¸æ˜¯ wfs_advanced
        "service_type": "WFS",
        "layer_info": basic_info,
        
        # æ•°æ®ä¿¡æ¯
        "geojson_data": geojson_data,
        "feature_count": len(features),
        
        # å‡ ä½•å’Œå±æ€§ä¿¡æ¯
        "geometry_type": capabilities.get("geometry_type") or (list(geometry_types)[0] if geometry_types else None),
        "geometry_types": list(geometry_types),
        "attributes": capabilities.get("attributes", []),
        
        # å¢å¼ºçš„è¿‡æ»¤ä¿¡æ¯
        "filter_info": {
            **filter_info,
            "has_advanced_filter": filter_info.get("mode") != "none",
            "filter_complexity": filter_info.get("complexity", "simple"),
            "optimization_level": len(filter_info.get("optimizations", []))
        },
        
        # æ€§èƒ½ä¿¡æ¯
        "performance_info": {
            **result_analysis,
            "query_config": query_config,
            "supports_advanced_filtering": True,
            "supports_multi_attribute": True,
            "supports_performance_optimization": True
        },
        
        # ç©ºé—´ä¿¡æ¯
        "bbox": capabilities.get("bbox", {}),
        "crs_list": capabilities.get("crs_list", ["EPSG:4326"]),
        "default_crs": capabilities.get("default_crs", "EPSG:4326"),
        
        # WFSå‚æ•°
        "wfs_params": wfs_params,
        "queryable": True,
        
        # æ ·å¼
        "style": _get_default_style(geometry_types),
        
        # å…ƒæ•°æ®
        "metadata": {
            "source": "advanced_wfs_tool_v2",
            "version": "2.0",
            "supports_multi_attribute_filter": True,
            "supports_performance_optimization": True,
            "supports_smart_suggestions": True,
            "filter_capabilities": {
                "operators": ["=", "!=", ">", "<", ">=", "<=", "LIKE", "IN", "BETWEEN"],
                "logic_operators": ["AND", "OR"],
                "performance_modes": ["balanced", "speed", "accuracy", "minimal"]
            }
        }
    }




async def _get_layer_info_simplified(layer_name: str, ctx: Optional[Context]) -> Dict[str, Any]:
    """ä»layer_registryèµ„æºè·å–å›¾å±‚è¯¦ç»†ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
    
    Args:
        layer_name: å›¾å±‚åç§°
        ctx: FastMCPä¸Šä¸‹æ–‡å¯¹è±¡
        
    Returns:
        å›¾å±‚è¯¦ç»†ä¿¡æ¯å­—å…¸
        
    Raises:
        ValueError: å½“å›¾å±‚ä¸å­˜åœ¨æ—¶
        Exception: èµ„æºè®¿é—®é”™è¯¯æ—¶
    """
    try:
        # æ„å»ºèµ„æºURI
        layer_resource_uri = f"ogc://layer/{layer_name}"
        
        if ctx:
            await ctx.debug(f"ğŸ” è·å–å›¾å±‚ä¿¡æ¯: {layer_resource_uri}")
        
        # é€šè¿‡ä¸Šä¸‹æ–‡è¯»å–èµ„æº
        layer_info_raw = await ctx.read_resource(layer_resource_uri)
        
        # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
        if isinstance(layer_info_raw, str):
            layer_info = json.loads(layer_info_raw)
        elif isinstance(layer_info_raw, dict):
            layer_info = layer_info_raw
        elif isinstance(layer_info_raw, list):
            if len(layer_info_raw) == 1:
                item = layer_info_raw[0]
                if hasattr(item, 'content'):
                    layer_info = json.loads(item.content)
                elif isinstance(item, dict):
                    layer_info = item
                else:
                    layer_info = json.loads(str(item))
            else:
                raise Exception(f"èµ„æºè¿”å›äº†æ„å¤–çš„åˆ—è¡¨æ ¼å¼: {layer_info_raw}")
        else:
            if hasattr(layer_info_raw, 'content'):
                layer_info = json.loads(layer_info_raw.content)
            else:
                layer_info = json.loads(str(layer_info_raw))
        
        # ç¡®ä¿layer_infoæ˜¯å­—å…¸ç±»å‹
        if not isinstance(layer_info, dict):
            raise Exception(f"èµ„æºè¿”å›çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼ŒæœŸæœ›å­—å…¸ï¼Œå®é™…: {type(layer_info)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if "error" in layer_info:
            suggestions = layer_info.get("suggestions", [])
            error_msg = layer_info["error"]
            if suggestions:
                error_msg += f"\nå»ºè®®çš„å›¾å±‚åç§°: {', '.join(suggestions[:5])}"
            raise ValueError(error_msg)
        
        return layer_info
        
    except json.JSONDecodeError as e:
        raise Exception(f"è§£æå›¾å±‚ä¿¡æ¯å¤±è´¥: {str(e)}")
    except Exception as e:
        if "ValueError" in str(type(e)):
            raise
        raise Exception(f"è·å–å›¾å±‚ä¿¡æ¯å¤±è´¥: {str(e)}")


def _validate_wfs_support(layer_info: Dict[str, Any], layer_name: str) -> bool:
    """éªŒè¯å›¾å±‚æ˜¯å¦æ”¯æŒWFSæœåŠ¡
    
    Args:
        layer_info: å›¾å±‚ä¿¡æ¯å­—å…¸
        layer_name: å›¾å±‚åç§°
        
    Returns:
        æ˜¯å¦æ”¯æŒWFSæœåŠ¡
    """
    # æ£€æŸ¥åŸºç¡€ä¿¡æ¯ä¸­çš„æœåŠ¡ç±»å‹
    basic_info = layer_info.get("basic_info", {})
    service_type = basic_info.get("service_type", "").upper()
    
    # æ£€æŸ¥æ”¯æŒçš„æœåŠ¡åˆ—è¡¨
    metadata = layer_info.get("metadata", {})
    supported_services = metadata.get("supported_services", [])
    
    # æ£€æŸ¥è®¿é—®å‚æ•°ä¸­æ˜¯å¦æœ‰WFSé…ç½®
    access_params = layer_info.get("access_parameters", {})
    has_wfs_params = "wfs" in access_params
    
    # ä»»ä¸€æ¡ä»¶æ»¡è¶³å³è®¤ä¸ºæ”¯æŒWFS
    return (
        service_type == "WFS" or
        "WFS" in supported_services or
        has_wfs_params
    )


def _extract_attributes_from_resource(layer_info: Dict[str, Any], ctx: Optional[Context]) -> List[str]:
    """ä»èµ„æºä¿¡æ¯ä¸­æå–å±æ€§åˆ—è¡¨
    
    Args:
        layer_info: å›¾å±‚ä¿¡æ¯å­—å…¸
        ctx: MCPä¸Šä¸‹æ–‡
        
    Returns:
        å±æ€§åç§°åˆ—è¡¨
    """
    attributes = []
    
    # ä¼˜å…ˆçº§1ï¼šè¯¦ç»†èƒ½åŠ›ä¿¡æ¯ä¸­çš„WFSç‰¹å¾æ¨¡å¼å±æ€§
    detailed_capabilities = layer_info.get("detailed_capabilities", {})
    wfs_details = detailed_capabilities.get("wfs", {})
    feature_schema = wfs_details.get("feature_schema", {})
    
    if feature_schema.get("attributes"):
        attributes.extend(feature_schema["attributes"])
    
    # ä¼˜å…ˆçº§2ï¼šè¯¦ç»†èƒ½åŠ›ä¿¡æ¯ä¸­çš„WFSå±æ€§
    if not attributes and wfs_details.get("attributes"):
        attributes.extend(wfs_details["attributes"])
    
    # ä¼˜å…ˆçº§3ï¼šåŸºç¡€èƒ½åŠ›ä¿¡æ¯ä¸­çš„å±æ€§
    if not attributes:
        capabilities = layer_info.get("capabilities", {})
        if capabilities.get("attributes"):
            attributes.extend(capabilities["attributes"])
    
    # å»é‡å¹¶è¿‡æ»¤ç©ºå€¼ï¼Œå¤„ç†å¯èƒ½çš„å­—å…¸æ ¼å¼å±æ€§
    unique_attributes = []
    seen = set()
    for attr in attributes:
        # å¤„ç†ä¸åŒçš„å±æ€§æ ¼å¼
        attr_name = None
        if isinstance(attr, str):
            attr_name = attr
        elif isinstance(attr, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–å±æ€§å
            attr_name = attr.get("name") or attr.get("attribute") or attr.get("field")
        
        # ç¡®ä¿å±æ€§åæ˜¯å­—ç¬¦ä¸²ä¸”ä¸ä¸ºç©º
        if attr_name and isinstance(attr_name, str) and attr_name.strip():
            attr_name = attr_name.strip()
            if attr_name not in seen:
                unique_attributes.append(attr_name)
                seen.add(attr_name)
    
    return unique_attributes


def _smart_match_attribute(
    target_attr: str, 
    available_attributes: List[str], 
    ctx: Optional[Context]
) -> Optional[str]:
    """æ™ºèƒ½å±æ€§åŒ¹é…
    
    Args:
        target_attr: ç›®æ ‡å±æ€§å
        available_attributes: å¯ç”¨å±æ€§åˆ—è¡¨
        ctx: MCPä¸Šä¸‹æ–‡
        
    Returns:
        åŒ¹é…çš„å±æ€§åï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ™è¿”å›None
    """
    if not target_attr or not available_attributes:
        return None
    
    target_lower = target_attr.lower()
    
    # 1. ç²¾ç¡®åŒ¹é…
    if target_attr in available_attributes:
        return target_attr
    
    # 2. å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
    for attr in available_attributes:
        if attr.lower() == target_lower:
            return attr
    
    # 3. åŒ…å«åŒ¹é…ï¼ˆç›®æ ‡å±æ€§åŒ…å«åœ¨å¯ç”¨å±æ€§ä¸­ï¼‰
    for attr in available_attributes:
        if target_lower in attr.lower():
            return attr
    
    # 4. è¢«åŒ…å«åŒ¹é…ï¼ˆå¯ç”¨å±æ€§åŒ…å«åœ¨ç›®æ ‡å±æ€§ä¸­ï¼‰
    for attr in available_attributes:
        if attr.lower() in target_lower:
            return attr
    
    return None

def _get_default_style(geometry_types: set) -> Dict[str, Any]:
    """æ ¹æ®å‡ ä½•ç±»å‹è·å–é»˜è®¤æ ·å¼
    
    Args:
        geometry_types: å‡ ä½•ç±»å‹é›†åˆ
        
    Returns:
        é»˜è®¤æ ·å¼å­—å…¸
    """
    # åŸºç¡€æ ·å¼é…ç½®
    base_style = {
        "color": "#3388ff",
        "weight": 3,
        "opacity": 0.8,
        "fillColor": "#3388ff",
        "fillOpacity": 0.2
    }
    
    # æ ¹æ®å‡ ä½•ç±»å‹è°ƒæ•´æ ·å¼
    if "Point" in geometry_types or "MultiPoint" in geometry_types:
        # ç‚¹æ ·å¼
        base_style.update({
            "radius": 6,
            "fillOpacity": 0.6,
            "weight": 2
        })
    elif "LineString" in geometry_types or "MultiLineString" in geometry_types:
        # çº¿æ ·å¼
        base_style.update({
            "weight": 4,
            "fillOpacity": 0.0  # çº¿ä¸éœ€è¦å¡«å……
        })
    elif "Polygon" in geometry_types or "MultiPolygon" in geometry_types:
        # é¢æ ·å¼
        base_style.update({
            "weight": 2,
            "fillOpacity": 0.3
        })
    
    return base_style    